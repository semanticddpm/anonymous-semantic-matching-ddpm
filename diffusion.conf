dataset: {
    name: ffhq
    path: data/ffhq_lmdb
    resolution: 256
    refpath: reference/face
}

model: {
    in_channel: 3
    channel: 128
    channel_multiplier: [1, 1, 2, 2, 4, 4]
    n_res_blocks: 2
    attn_strides: [16]
    attn_heads: 1
    use_affine_time: false
    dropout: 0.0
    fold: 1
}

diffusion: {
    beta_schedule: {
        schedule: linear
        n_timestep: 1000
        linear_start: 1e-4
        linear_end: 2e-2
    }
}

training: {
    n_iter = 1000000
    optimizer: {
        type: adam
        lr: 2e-5
    }
    scheduler: {
        type: cycle
        lr: 2e-5
        n_iter: 1000000
        warmup: 5000
        decay: [linear, flat]
    }
    dataloader: {
        batch_size: 16
        num_workers: 2
        drop_last: true
    }
}

evaluate: {
    wandb: false
    log_every: 10
    save_every: 5000
    valid_every: 5000
    n_sample: 10
    semantic_level1: 32
    semantic_level2: 32
    ckpt: checkpoint/ffhq_256_1200000.pt
    mode: generate
}

